{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYsSfUdrW3mXKCnU6IupkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdapoy/Machine-Learning-week-8-16/blob/main/Ch17_REPRESENTATION_LEARNING_AND_GENERATIVE_LEARNING_USING_AUTOENCODERS_AND_GANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAPORAN ANALISIS BUKU\n",
        "**Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (Aurélien Géron)**\n",
        "\n",
        "**BAB 17: REPRESENTATION LEARNING AND GENERATIVE LEARNING USING AUTOENCODERS AND GANS**\n",
        "\n",
        "## 1. Pendahuluan\n",
        "[cite_start]Bab 17 dari buku ini memperkenalkan dua konsep penting dalam Machine Learning tak terawasi (unsupervised learning): *Autoencoders* dan *Generative Adversarial Networks* (GANs). [cite_start]Kedua model ini berfokus pada pembelajaran representasi data yang efisien (*representation learning*) dan kemampuan untuk menghasilkan data baru yang mirip dengan data pelatihan (*generative learning*). [cite_start]Meskipun memiliki tujuan yang serupa, pendekatan fundamental keduanya sangat berbeda.\n",
        "\n",
        "* [cite_start]**Autoencoder**: Belajar untuk menyalin inputnya sendiri ke outputnya dengan memaksa jaringan untuk mempelajari representasi data yang efisien melalui berbagai batasan, seperti membatasi ukuran representasi laten atau menambahkan *noise* ke input.\n",
        "* [cite_start]**GANs**: Terdiri dari dua jaringan saraf yang bersaing satu sama lain—sebuah generator yang mencoba menghasilkan data realistis dan sebuah diskriminator yang mencoba membedakan data asli dari yang palsu. [cite_start]Pendekatan pelatihan adversarial ini dianggap sebagai salah satu ide paling penting dalam Machine Learning baru-baru ini.\n",
        "\n",
        "## 2. Representasi Data yang Efisien (Efficient Data Representations)\n",
        "[cite_start]Bab ini membuka dengan analogi tentang bagaimana manusia cenderung mencari pola untuk menghafal urutan angka secara efisien, yang menjadi dasar pemahaman *Autoencoder*.\n",
        "\n",
        "### 2.1. Autoencoder\n",
        "* [cite_start]**Definisi**: Autoencoder adalah jaringan saraf tiruan yang mampu mempelajari representasi padat dari data input, yang disebut *latent representations* atau *codings*, tanpa pengawasan.\n",
        "* [cite_start]**Struktur**: Sebuah Autoencoder selalu terdiri dari dua bagian: sebuah *encoder* (atau *recognition network*) yang mengubah input menjadi representasi laten, diikuti oleh sebuah *decoder* (atau *generative network*) yang mengubah representasi internal menjadi output yang diharapkan mirip dengan input asli. [cite_start]Jumlah neuron di lapisan output harus sama dengan jumlah input. [cite_start]Output sering disebut rekonstruksi karena Autoencoder mencoba merekonstruksi input.\n",
        "* [cite_start]**Reconstruction Loss**: Fungsi biaya mengandung *reconstruction loss* yang menghukum model ketika rekonstruksi (output) berbeda dari input.\n",
        "* [cite_start]**Undercomplete Autoencoder**: Autoencoder yang memiliki dimensi lapisan *coding* lebih rendah daripada data input. [cite_start]Ini memaksa Autoencoder untuk mempelajari fitur-fitur penting dalam data dan mengabaikan yang tidak penting, karena tidak dapat secara trivial menyalin input langsung ke output.\n",
        "* [cite_start]**Pembelajaran Mandiri (*Self-supervised Learning*)**: Autoencoder dapat dianggap sebagai bentuk pembelajaran mandiri, di mana label dihasilkan secara otomatis (sama dengan input).\n",
        "\n",
        "## 3. PCA dengan Undercomplete Linear Autoencoder\n",
        "[cite_start]Jika Autoencoder hanya menggunakan aktivasi linear dan fungsi biaya *Mean Squared Error* (MSE), maka ia akan melakukan *Principal Component Analysis* (PCA).\n",
        "\n",
        "* **Implementasi**: Contoh kode menunjukkan pembangunan Autoencoder Sequential sederhana dengan satu lapisan `Dense` di encoder (dari 3 input ke 2 output) dan satu lapisan `Dense` di decoder (dari 2 input ke 3 output). [cite_start]Model ini dikompilasi dengan MSE sebagai loss dan SGD sebagai optimizer.\n",
        "* [cite_start]**Pelatihan**: Data pelatihan digunakan sebagai input dan juga sebagai target, mencerminkan sifat pembelajaran mandiri (*self-supervised learning*) dari Autoencoder.\n",
        "* [cite_start]**Hasil**: Autoencoder menemukan bidang 2D terbaik untuk memproyeksikan data 3D, mempertahankan varians sebanyak mungkin, mirip dengan hasil PCA.\n",
        "\n",
        "## 4. Stacked Autoencoders (Deep Autoencoders)\n",
        "[cite_start]Autoencoder dapat memiliki beberapa lapisan tersembunyi, yang disebut *stacked autoencoders* atau *deep autoencoders*. [cite_start]Menambahkan lapisan membantu Autoencoder mempelajari *codings* yang lebih kompleks.\n",
        "\n",
        "* [cite_start]**Risiko**: Jika Autoencoder terlalu \"kuat\" atau kompleks tanpa batasan yang memadai, ia mungkin hanya belajar untuk menyalin input secara trivial tanpa mempelajari representasi data yang bermakna.\n",
        "* [cite_start]**Arsitektur Umum**: Biasanya simetris terhadap lapisan *coding* pusat. [cite_start]Contoh untuk Fashion MNIST disebutkan memiliki 784 input, kemudian lapisan tersembunyi 100 neuron, lapisan *coding* 30 neuron, lalu lapisan tersembunyi 100 neuron, dan output 784 neuron.\n",
        "* [cite_start]**Implementasi Keras**: Model dibagi menjadi `stacked_encoder` dan `stacked_decoder`. [cite_start]Encoder meratakan gambar 28x28 menjadi vektor 784, kemudian melalui dua lapisan `Dense` (100 dan 30 unit) dengan fungsi aktivasi SELU. [cite_start]Decoder mengambil *codings* 30 unit, melalui dua lapisan `Dense` (100 dan 28*28 unit) dan mengubah bentuk output menjadi 28x28. [cite_start]`binary_crossentropy` digunakan sebagai fungsi biaya, memperlakukan rekonstruksi sebagai masalah klasifikasi biner multilabel per piksel, yang cenderung mempercepat konvergensi. [cite_start]Data pelatihan (`X_train`) digunakan sebagai input dan target.\n",
        "\n",
        "## 5. Visualisasi Rekonstruksi\n",
        "\n",
        "Visualisasi rekonstruksi adalah cara penting untuk memeriksa apakah Autoencoder dilatih dengan benar. [cite_start]Perbedaan yang terlalu signifikan antara input asli dan output yang direkonstruksi menunjukkan Autoencoder mungkin belum terlatih dengan baik.\n",
        "\n",
        "### 5.1. Visualisasi Dataset Fashion MNIST\n",
        "[cite_start]Autoencoder dapat digunakan untuk mereduksi dimensi dataset. [cite_start]Sebagai contoh, encoder dari *stacked autoencoder* dapat mengurangi dimensi data menjadi 30, kemudian algoritma t-SNE digunakan untuk memproyeksikan data ke 2D untuk visualisasi.\n",
        "\n",
        "## 6. Unsupervised Pretraining dengan Stacked Autoencoders\n",
        "[cite_start]Autoencoder sangat berguna untuk *unsupervised pretraining*, terutama ketika data berlabel terbatas.\n",
        "\n",
        "* [cite_start]**Skenario**: Jika Anda memiliki tugas *supervised* yang kompleks tetapi data berlabelnya sedikit, sementara data tak berlabelnya banyak, Anda dapat melatih *stacked autoencoder* pada seluruh data (berlabel dan tak berlabel).\n",
        "* [cite_start]**Proses**: Setelah Autoencoder dilatih, bagian *encoder*-nya dapat digunakan kembali sebagai lapisan awal untuk jaringan saraf yang akan dilatih untuk tugas *supervised* menggunakan data berlabel. [cite_start]Lapisan-lapisan yang digunakan kembali ini seringkali dibekukan (*frozen*) pada awalnya, terutama jika data berlabel sedikit.\n",
        "* [cite_start]**Sejarah**: Teknik ini, terutama dengan *Restricted Boltzmann Machines* (RBMs) atau Autoencoder, penting dalam kebangkitan Deep Learning pada tahun 2006.\n",
        "\n",
        "## 7. Teknik Pelatihan Stacked Autoencoders\n",
        "Bab ini juga membahas beberapa teknik tambahan untuk melatih *stacked autoencoders*:\n",
        "\n",
        "### 7.1. Tying Weights (Mengikat Bobot)\n",
        "* [cite_start]**Konsep**: Jika Autoencoder simetris, bobot lapisan *decoder* dapat diikat (dijadikan sama dengan transpos) bobot lapisan *encoder* yang sesuai. [cite_start]Jika $W_L$ adalah bobot lapisan ke-$L$, maka bobot lapisan *decoder* ke-$(N-L+1)$ adalah $W_L^T$.\n",
        "* [cite_start]**Manfaat**: Mengurangi separuh jumlah bobot dalam model, mempercepat pelatihan, dan membatasi risiko *overfitting*.\n",
        "* [cite_start]**Implementasi Keras**: Memerlukan *custom layer* seperti `DenseTranspose` yang menggunakan bobot dari lapisan `Dense` lain yang sudah ada, lalu di-transpos.\n",
        "\n",
        "### 7.2. Training One Autoencoder at a Time (Greedy Layer-wise Training)\n",
        "* [cite_start]**Konsep**: Melatih satu Autoencoder dangkal pada satu waktu, lalu menyusunnya menjadi satu *stacked autoencoder*.\n",
        "* **Proses**: Melatih Autoencoder pertama untuk merekonstruksi input. Kemudian, output *encoder* pertama digunakan sebagai input untuk melatih Autoencoder kedua, dan seterusnya. [cite_start]Setelah semua Autoencoder dilatih, lapisan tersembunyi dari setiap *encoder* dan lapisan output *decoder* disusun menjadi Autoencoder bertumpuk akhir.\n",
        "* [cite_start]**Sejarah**: Teknik ini memungkinkan pelatihan jaringan dalam secara efisien sebelum teknik pelatihan *end-to-end* ditemukan.\n",
        "\n",
        "## 8. Jenis-jenis Autoencoder Lainnya\n",
        "Autoencoder tidak terbatas pada jaringan *dense*; ada juga varian untuk jenis data atau batasan yang berbeda:\n",
        "\n",
        "### 8.1. Convolutional Autoencoders\n",
        "* [cite_start]**Skenario**: Digunakan untuk gambar. [cite_start]Encoder adalah CNN biasa (lapisan konvolusional dan *pooling*), sementara decoder melakukan operasi kebalikan (menggunakan lapisan *transpose convolutional* atau *upsampling*) untuk meningkatkan resolusi gambar dan mengurangi kedalaman fitur.\n",
        "\n",
        "### 8.2. Recurrent Autoencoders\n",
        "* [cite_start]**Skenario**: Digunakan untuk data sekuensial seperti deret waktu atau teks. [cite_start]Encoder biasanya adalah RNN *sequence-to-vector* yang mengompres sekuens input menjadi satu vektor. [cite_start]Decoder adalah RNN *vector-to-sequence* yang melakukan kebalikan.\n",
        "\n",
        "### 8.3. Denoising Autoencoders\n",
        "* [cite_start]**Skenario**: Memaksa Autoencoder mempelajari fitur-fitur yang berguna dengan menambahkan *noise* pada input dan melatihnya untuk merekonstruksi input asli yang bebas *noise*.\n",
        "* [cite_start]**Jenis Noise**: Bisa berupa *Gaussian noise* atau mematikan input secara acak (mirip *dropout*).\n",
        "* [cite_start]**Manfaat**: Selain untuk visualisasi data dan *unsupervised pretraining*, juga efektif untuk menghilangkan *noise* dari gambar.\n",
        "\n",
        "### 8.4. Sparse Autoencoders\n",
        "* [cite_start]**Skenario**: Mendorong Autoencoder untuk mengurangi jumlah neuron aktif di lapisan *coding* (sparsitas) dengan menambahkan term yang sesuai pada fungsi biaya.\n",
        "* [cite_start]**Tujuan**: Memaksa setiap neuron di lapisan *coding* untuk merepresentasikan fitur yang berguna.\n",
        "* **Pendekatan**:\n",
        "    * Menggunakan fungsi aktivasi sigmoid di lapisan *coding* (untuk membatasi nilai coding antara 0 dan 1) dan lapisan *coding* yang besar (misalnya, 300 unit).\n",
        "    * [cite_start]Menambahkan regularisasi L1 pada aktivasi lapisan *coding* (menggunakan `ActivityRegularization` atau `activity_regularizer`).\n",
        "    * Pendekatan yang lebih baik: Menghukum model ketika sparsitas terukur (aktivasi rata-rata neuron) berbeda dari sparsitas target yang diinginkan, seringkali menggunakan *Kullback–Leibler (KL) divergence* sebagai fungsi kerugian.\n",
        "\n",
        "## 9. Variational Autoencoders (VAEs)\n",
        "[cite_start]Variational Autoencoders (VAEs) adalah kategori penting dari Autoencoder yang diperkenalkan pada tahun 2013, yang kemudian menjadi sangat populer.\n",
        "\n",
        "* **Sifat Khusus**:\n",
        "    * [cite_start]**Probabilistic Autoencoders**: Outputnya sebagian ditentukan oleh peluang, bahkan setelah pelatihan.\n",
        "    * [cite_start]**Generative Autoencoders**: Mampu menghasilkan instansi baru yang sangat mirip dengan data pelatihan.\n",
        "* **Mekanisme**: Encoder menghasilkan *mean coding* ($\\mu$) dan *standard deviation* ($\\sigma$) untuk input yang diberikan. [cite_start]*Coding* aktual kemudian diambil sampelnya secara acak dari distribusi Gaussian dengan $\\mu$ dan $\\sigma$ tersebut, yang kemudian didekode oleh *decoder*.\n",
        "* **Fungsi Biaya**: Terdiri dari dua bagian:\n",
        "    1.  [cite_start]**Reconstruction Loss**: Loss standar yang mendorong Autoencoder untuk mereproduksi inputnya.\n",
        "    2.  **Latent Loss**: Mendorong *coding* agar menyerupai sampel dari distribusi Gaussian sederhana. [cite_start]Ini adalah *KL divergence* antara distribusi target (Gaussian) dan distribusi aktual *coding*.\n",
        "* [cite_start]**Pembangkitan Gambar**: Setelah dilatih, VAE dapat menghasilkan gambar yang mirip dengan item fashion dengan mengambil sampel *coding* acak dari distribusi Gaussian dan mendekodekannya.\n",
        "* **Interpolasi Semantik**: Memungkinkan interpolasi antara dua gambar pada tingkat *coding* (ruang laten), menghasilkan gambar perantara yang mulus dan realistis.\n",
        "\n",
        "## 10. Generative Adversarial Networks (GANs)\n",
        "[cite_start]Generative Adversarial Networks (GANs) diperkenalkan pada tahun 2014 dan menjadi sangat terkenal karena kemampuannya menghasilkan gambar yang sangat realistis.\n",
        "\n",
        "* [cite_start]**Struktur**: GANs terdiri dari dua jaringan saraf yang bersaing satu sama lain:\n",
        "    * **Generator**: Menerima input distribusi acak (misalnya, Gaussian) dan menghasilkan data, biasanya gambar. [cite_start]Generator bertujuan untuk menghasilkan gambar yang tampak cukup nyata untuk menipu diskriminator.\n",
        "    * **Discriminator**: Menerima gambar (baik palsu dari generator atau asli dari dataset pelatihan) sebagai input, dan harus menebak apakah gambar tersebut palsu atau asli. [cite_start]Diskriminator mencoba membedakan gambar palsu dari gambar asli.\n",
        "* **Proses Pelatihan (Dua Fase per Iterasi)**:\n",
        "    1.  [cite_start]**Fase Pelatihan Diskriminator**: Diskriminator dilatih pada batch yang berisi gambar asli (label 1) dan gambar palsu yang dihasilkan generator (label 0). [cite_start]Bobot generator dibekukan selama fase ini.\n",
        "    2.  **Fase Pelatihan Generator**: Generator dilatih pada batch gambar palsu yang baru dihasilkan. [cite_start]Diskriminator digunakan untuk menilai gambar-gambar ini, tetapi semua label diatur ke 1 (asli). [cite_start]Bobot diskriminator dibekukan. [cite_start]Generator bertujuan untuk membuat diskriminator *secara salah* percaya bahwa gambar palsu itu asli.\n",
        "* **Kesulitan Pelatihan GANs**:\n",
        "    * [cite_start]**Mode Collapse**: Generator menghasilkan output yang kurang beragam seiring waktu, hanya berfokus pada beberapa jenis output yang berhasil menipu diskriminator.\n",
        "    * [cite_start]**Ketidakstabilan Parameter**: Bobot generator dan diskriminator dapat berosilasi dan menjadi tidak stabil karena persaingan yang konstan, menyebabkan pelatihan tiba-tiba menyimpang.\n",
        "    * [cite_start]**Sensitivitas Hiperparameter**: GANs sangat sensitif terhadap pilihan hiperparameter.\n",
        "* **Teknik Mengatasi Kesulitan**:\n",
        "    * [cite_start]**Experience Replay**: Menyimpan gambar yang dihasilkan generator dari iterasi sebelumnya dalam *replay buffer* untuk melatih diskriminator, mengurangi *overfitting* pada output generator terbaru.\n",
        "    * [cite_start]**Mini-batch Discrimination**: Mengukur kesamaan gambar dalam batch dan memberikan statistik ini ke diskriminator untuk mendorong generator menghasilkan keragaman yang lebih besar.\n",
        "\n",
        "## 11. Deep Convolutional GANs (DCGANs)\n",
        "[cite_start]DCGANs adalah arsitektur GAN yang diusulkan pada tahun 2015, yang berhasil mengatasi banyak kesulitan pelatihan GAN untuk gambar yang lebih besar.\n",
        "\n",
        "* **Pedoman Utama**:\n",
        "    * [cite_start]Mengganti lapisan *pooling* dengan *strided convolutions* (pada diskriminator) dan *transposed convolutions* (pada generator).\n",
        "    * [cite_start]Menggunakan *Batch Normalization* pada generator (kecuali lapisan output) dan diskriminator (kecuali lapisan input).\n",
        "    * [cite_start]Menghilangkan lapisan *fully connected hidden* untuk arsitektur yang lebih dalam.\n",
        "    * [cite_start]Menggunakan aktivasi ReLU di generator (kecuali lapisan output, yang menggunakan tanh).\n",
        "    * [cite_start]Menggunakan aktivasi Leaky ReLU di semua lapisan diskriminator.\n",
        "* [cite_start]**Manfaat**: Mampu menghasilkan gambar yang cukup realistis dan mempelajari representasi laten yang bermakna (misalnya, aritmetika vektor untuk konsep visual).\n",
        "* [cite_start]**Conditional GAN (CGAN)**: Menambahkan kelas sebagai input ekstra ke generator dan diskriminator memungkinkan kontrol atas kelas gambar yang dihasilkan.\n",
        "\n",
        "## 12. Progressive Growing of GANs\n",
        "[cite_start]Teknik yang diusulkan pada tahun 2018 ini berfokus pada peningkatan kualitas, stabilitas, dan variasi gambar yang dihasilkan.\n",
        "\n",
        "* [cite_start]**Konsep**: Memulai pelatihan dengan menghasilkan gambar kecil, lalu secara bertahap menambahkan lapisan konvolusional ke generator dan diskriminator untuk menghasilkan gambar yang semakin besar (misalnya, dari 4x4 hingga 1024x1024).\n",
        "* [cite_start]**Fade-in/Fade-out**: Lapisan baru secara bertahap \"dimasukkan\" dengan bobot $\\alpha$, sementara lapisan output asli \"dikeluarkan\" dengan bobot $1-\\alpha$.\n",
        "* **Teknik Tambahan untuk Stabilitas**:\n",
        "    * [cite_start]**Minibatch Standard Deviation Layer**: Ditambahkan di dekat akhir diskriminator untuk mendorong generator menghasilkan output yang lebih beragam, mengurangi risiko *mode collapse*.\n",
        "    * **Equalized Learning Rate**: Menginisialisasi bobot dengan distribusi Gaussian sederhana tetapi menskalakan bobot saat runtime. [cite_start]Ini memastikan jangkauan dinamis yang sama untuk semua parameter, mempercepat dan menstabilkan pelatihan.\n",
        "    * **Pixelwise Normalization Layer**: Ditambahkan setelah setiap lapisan konvolusional di generator untuk menghindari ledakan aktivasi.\n",
        "\n",
        "## 13. StyleGANs\n",
        "[cite_start]StyleGANs, yang diperkenalkan pada tahun 2018 oleh tim Nvidia yang sama, mencapai *state-of-the-art* dalam generasi gambar resolusi tinggi dengan menggabungkan teknik *style transfer*.\n",
        "\n",
        "* **Struktur Generator**: Terdiri dari dua jaringan:\n",
        "    * [cite_start]**Mapping Network**: MLP delapan lapisan yang memetakan representasi laten (coding `z`) ke vektor gaya `w`. [cite_start]Vektor `w` ini kemudian diubah melalui beberapa transformasi afin untuk menghasilkan vektor gaya tambahan yang mengontrol gaya gambar pada berbagai tingkat (misalnya, warna rambut hingga fitur tingkat tinggi seperti usia).\n",
        "    * **Synthesis Network**: Bertanggung jawab menghasilkan gambar. [cite_start]Menerima input konstan yang dipelajari dan memprosesnya melalui lapisan konvolusional dan *upsampling*.\n",
        "* **Fitur Utama**:\n",
        "    * [cite_start]**Penambahan Noise**: *Noise* ditambahkan ke input dan semua output lapisan konvolusional (sebelum fungsi aktivasi) untuk menambahkan *stochasticity* (kebetulan) yang diperlukan pada gambar yang dihasilkan, seperti posisi bintik atau rambut.\n",
        "    * **Adaptive Instance Normalization (AdaIN)**: Digunakan setelah setiap lapisan *noise*, yang menstandardisasi setiap *feature map* secara independen, lalu menggunakan vektor gaya untuk menentukan skala dan offset setiap *feature map*.\n",
        "    * [cite_start]**Mixing Regularization (Style Mixing)**: Menggunakan dua *coding* berbeda untuk menghasilkan gambar (satu untuk level awal, yang lain untuk level berikutnya), yang mencegah jaringan mengasumsikan korelasi gaya antar level, mendorong lokalisasi gaya.\n",
        "\n",
        "## 14. Kesimpulan Bab 17\n",
        "Bab 17 memberikan gambaran mendalam tentang *Autoencoders* dan GANs, dua pilar utama dalam pembelajaran tak terawasi dan generatif. [cite_start]Autoencoder fokus pada pembelajaran representasi yang efisien melalui rekonstruksi input dengan batasan, yang dapat digunakan untuk reduksi dimensi, *pretraining*, atau menghasilkan data yang cenderung *fuzzy*. [cite_start]Sebaliknya, GANs, dengan arsitektur adversarial antara generator dan diskriminator, menghasilkan gambar yang sangat realistis, meskipun proses pelatihannya lebih kompleks dan rentan terhadap masalah seperti *mode collapse*. [cite_start]Perkembangan teknik seperti DCGANs, Progressive Growing of GANs, dan StyleGANs menunjukkan bagaimana inovasi arsitektur dan strategi pelatihan telah mendorong kemampuan GANs hingga menghasilkan gambar yang nyaris tak bisa dibedakan dari aslinya. Pemahaman tentang kedua jenis model ini sangat penting bagi setiap praktisi *Machine Learning* yang ingin mendalami area pembelajaran representasi dan sintesis data.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vwknUEjK0QNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REPRODUCE CODE"
      ],
      "metadata": {
        "id": "3-i5YSyr33IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing PCA with an Undercomplete Linear Autoencoder"
      ],
      "metadata": {
        "id": "VcYH96X43_In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3gyb-dB4iGg",
        "outputId": "2a866e01-8418-44ea-e7c9-4f87b7f8c5be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
        "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
        "autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.1))\n",
        "\n",
        "# history = autoencoder.fit(X_train, X_train, epochs=20)\n",
        "# codings = encoder.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOHaTAnc34yj",
        "outputId": "e7b85dbc-fac4-409f-e977-4226bd6d3dab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Stacked Autoencoder Using Keras"
      ],
      "metadata": {
        "id": "UdaL30VZ4SlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"),\n",
        "])\n",
        "\n",
        "stacked_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
        "                   optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
        "\n",
        "# history = stacked_ae.fit(X_train, X_train, epochs=10,\n",
        "#                          validation_data=[X_valid, X_valid])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-LBYasH4TVM",
        "outputId": "a61c031a-b64b-45dc-9440-ae0d0cba06a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Reconstructions"
      ],
      "metadata": {
        "id": "PemgQRos5Wmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def show_reconstructions(model, n_images=5):\n",
        "    # Dummy X_valid for demonstration\n",
        "    import numpy as np\n",
        "    X_valid = np.random.rand(n_images, 28, 28)\n",
        "\n",
        "    reconstructions = model.predict(X_valid[:n_images])\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plot_image(X_valid[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plot_image(reconstructions[image_index])\n",
        "\n",
        "# show_reconstructions(stacked_ae)"
      ],
      "metadata": {
        "id": "rhBVOMSz5Xny"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Fashion MNIST Dataset"
      ],
      "metadata": {
        "id": "DBylL_f95ZCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "# Dummy data for demonstration\n",
        "# X_valid_compressed = stacked_encoder.predict(X_valid)\n",
        "X_valid_compressed = np.random.rand(100, 30)\n",
        "y_valid = np.random.randint(0, 10, 100)\n",
        "\n",
        "tsne = TSNE()\n",
        "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
        "\n",
        "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Nu2eMX3j5bSq",
        "outputId": "490afe1c-d94d-4b5c-aae2-421e1af64234"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7d85c8c76110>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tying Weights"
      ],
      "metadata": {
        "id": "R0KRWGHr5e4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom layer for tying weights\n",
        "class DenseTranspose(keras.layers.Layer):\n",
        "    def __init__(self, dense, activation=None, **kwargs):\n",
        "        self.dense = dense\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        # The bias shape should match the input dimension of the original dense layer.\n",
        "        # This is the last dimension of the dense layer's input shape.\n",
        "        # We assume the dense layer's input shape is available by this point.\n",
        "        self.biases = self.add_weight(name=\"bias\", initializer=\"zeros\",\n",
        "                                      shape=[self.dense.input_shape[-1]]) # Get shape from dense.input_shape\n",
        "\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Access the kernel directly and transpose it for the matrix multiplication\n",
        "        z = tf.matmul(inputs, self.dense.kernel, transpose_b=True)\n",
        "        return self.activation(z + self.biases)\n",
        "\n",
        "# Building the tied autoencoder\n",
        "dense_1 = keras.layers.Dense(100, activation=\"selu\")\n",
        "dense_2 = keras.layers.Dense(30, activation=\"selu\")\n",
        "\n",
        "tied_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    dense_1,\n",
        "    dense_2\n",
        "])\n",
        "\n",
        "tied_decoder = keras.models.Sequential([\n",
        "    DenseTranspose(dense_2, activation=\"selu\"), # This layer should have biases with shape [100]\n",
        "    DenseTranspose(dense_1, activation=\"sigmoid\"), # This layer should have biases with shape [784] (after Flatten)\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])"
      ],
      "metadata": {
        "id": "KsF3OiZU5gjn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Autoencoders"
      ],
      "metadata": {
        "id": "aGmwpB6E5lH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2)\n",
        "])\n",
        "\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"valid\",\n",
        "                                activation=\"selu\",\n",
        "                                input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\",\n",
        "                                activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\",\n",
        "                                activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQG-GQT85n6F",
        "outputId": "3b2b5abb-5156-4144-c274-9d6a7d96de81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv_transpose.py:94: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Autoencoders"
      ],
      "metadata": {
        "id": "-FQLLo6x5sbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recurrent_encoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
        "    keras.layers.LSTM(30)\n",
        "])\n",
        "\n",
        "recurrent_decoder = keras.models.Sequential([\n",
        "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
        "    keras.layers.LSTM(100, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
        "])\n",
        "\n",
        "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DONsIgLi5wOA",
        "outputId": "8542613c-7d83-4bb7-dd9b-497361589c53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/repeat_vector.py:29: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoising Autoencoders"
      ],
      "metadata": {
        "id": "bQStE5Wz50Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\")\n",
        "])\n",
        "\n",
        "dropout_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wQyqhVl5_Yy",
        "outputId": "abe437c5-f8a2-410e-9c39-4aac10819aa8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse Autoencoders"
      ],
      "metadata": {
        "id": "mkrep3QQ6B_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_l1_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(300, activation=\"sigmoid\"),\n",
        "    keras.layers.ActivityRegularization(l1=1e-3)\n",
        "])\n",
        "\n",
        "sparse_l1_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKxNYxmH6ET3",
        "outputId": "12761c37-456c-421f-f06d-fa5b5080218d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menggunakan KL Divergence"
      ],
      "metadata": {
        "id": "0VrEl96V6Fkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "kl_divergence = keras.losses.kullback_leibler_divergence\n",
        "\n",
        "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight, target=0.1):\n",
        "        self.weight = weight\n",
        "        self.target = target\n",
        "    def __call__(self, inputs):\n",
        "        mean_activities = K.mean(inputs, axis=0)\n",
        "        return self.weight * (\n",
        "            kl_divergence(self.target, mean_activities) +\n",
        "            kl_divergence(1. - self.target, 1. - mean_activities))\n",
        "    def get_config(self):\n",
        "        return {\"weight\": self.weight, \"target\": self.target}\n",
        "\n",
        "kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
        "\n",
        "sparse_kl_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n",
        "])\n",
        "\n",
        "sparse_kl_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwQUJ-AN6H4U",
        "outputId": "c7ee0de4-03c7-49c9-ca77-8e80e884f8b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Autoencoders"
      ],
      "metadata": {
        "id": "uiglextc6J2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n",
        "\n",
        "codings_size = 10\n",
        "\n",
        "# Encoder\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(codings_size)(z)\n",
        "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "variational_encoder = keras.Model(\n",
        "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "# Variational Autoencoder\n",
        "_, _, codings = variational_encoder(inputs)\n",
        "reconstructions = variational_decoder(codings)\n",
        "variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "# Add latent loss and compile\n",
        "latent_loss = -0.5 * K.sum(\n",
        "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
        "    axis=-1)\n",
        "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
        "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "# history = variational_ae.fit(X_train, X_train, epochs=50, batch_size=128,\n",
        "#                              validation_data=[X_valid, X_valid])"
      ],
      "metadata": {
        "id": "I9FDPBvg6MAT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Fashion MNIST Images"
      ],
      "metadata": {
        "id": "eTzJ8U4c6Qcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codings = tf.random.normal(shape=[12, codings_size])\n",
        "images = variational_decoder(codings).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRS_SBTV6SLs",
        "outputId": "0f453921-86e9-44b0-c62b-aed42f13e64d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_179']\n",
            "Received: inputs=Tensor(shape=(12, 10))\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codings_grid = tf.reshape(codings, [1, 3, 4, codings_size])\n",
        "larger_grid = tf.image.resize(codings_grid, size=[5, 7])\n",
        "interpolated_codings = tf.reshape(larger_grid, [-1, codings_size])\n",
        "images = variational_decoder(interpolated_codings).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HduO_Xmq6n7o",
        "outputId": "ed7a62bb-4bed-4ece-a6c5-6d2f7812ad52"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_179']\n",
            "Received: inputs=Tensor(shape=(35, 10))\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Adversarial Networks (GANs)"
      ],
      "metadata": {
        "id": "WFCwbs7F6q1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "codings_size = 30\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "# Compile\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "# Dataset\n",
        "batch_size = 32\n",
        "# dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "# dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "\n",
        "# Training loop\n",
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch in dataset:\n",
        "            # phase 1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase 2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "\n",
        "# train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFIJkwcV6rmx",
        "outputId": "00dfad3d-bb92-40af-98da-1e85cc660e29"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Convolutional GANs (DCGANs)"
      ],
      "metadata": {
        "id": "OVAwSxtx6uHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codings_size = 100\n",
        "\n",
        "# Generator\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                activation=\"selu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                activation=\"tanh\"),\n",
        "])\n",
        "\n",
        "# Discriminator\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "# Data Preprocessing\n",
        "# X_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGxUt_TX6uyo",
        "outputId": "222fce39-7e2f-4bdc-c02f-9d947902b819"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}